{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from keras.models import Model, Input, load_model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gear_defects = [0, 35, 76, 77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size\n",
    "size = [300, 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.904515027999878\n"
     ]
    }
   ],
   "source": [
    "# Load pre-processed dataset\n",
    "X_train = np.load('gears_train_300x400_0,76,77,35.npy')\n",
    "X_test = np.load('gears_test_300x400_0,76,77,35.npy')\n",
    "y_train = np.load('gears_ytrain_300x400_0,76,77,35.npy')\n",
    "y_test = np.load('gears_ytest_300x400_0,76,77,35.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 300, 400, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 300, 400, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 150, 200, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 200, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 200, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 150, 200, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 100, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 100, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 75, 100, 256)      295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 100, 256)      590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 75, 100, 256)      590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 50, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 50, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 50, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 50, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 37, 50, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 18, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 18, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 18, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 12, 512)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 9, 12, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 55296)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               28312064  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 43,290,308\n",
      "Trainable params: 43,290,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up architecture\n",
    "dropout = 0.5\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(input_shape = X_train[0].shape,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Dense(len(np.unique(y_train)), activation = \"softmax\"))\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping and best model checkpoint\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, min_delta=0.1, patience=40)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_weights_only=True, mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/262 [..............................] - ETA: 1:08 - loss: 1.2738 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1619s vs `on_train_batch_end` time: 0.3629s). Check your callbacks.\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9775 - accuracy: 0.7662\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75048, saving model to best_model.h5\n",
      "262/262 [==============================] - 152s 579ms/step - loss: 0.9775 - accuracy: 0.7662 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9722 - accuracy: 0.7714\n",
      "Epoch 00002: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 147s 560ms/step - loss: 0.9722 - accuracy: 0.7714 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9738 - accuracy: 0.7699\n",
      "Epoch 00003: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 147s 561ms/step - loss: 0.9738 - accuracy: 0.7699 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9733 - accuracy: 0.7704\n",
      "Epoch 00004: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 559ms/step - loss: 0.9733 - accuracy: 0.7704 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9727 - accuracy: 0.7709\n",
      "Epoch 00005: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 559ms/step - loss: 0.9727 - accuracy: 0.7709 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9776 - accuracy: 0.7661\n",
      "Epoch 00006: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 559ms/step - loss: 0.9776 - accuracy: 0.7661 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 7/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.7690\n",
      "Epoch 00007: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 559ms/step - loss: 0.9746 - accuracy: 0.7690 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 8/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9739 - accuracy: 0.7698\n",
      "Epoch 00008: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9739 - accuracy: 0.7698 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 9/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9732 - accuracy: 0.7705\n",
      "Epoch 00009: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9732 - accuracy: 0.7705 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 10/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9780 - accuracy: 0.7657\n",
      "Epoch 00010: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 559ms/step - loss: 0.9780 - accuracy: 0.7657 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 11/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.7686\n",
      "Epoch 00011: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 559ms/step - loss: 0.9751 - accuracy: 0.7686 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 12/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.7689\n",
      "Epoch 00012: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 147s 560ms/step - loss: 0.9747 - accuracy: 0.7689 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 13/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9749 - accuracy: 0.7688\n",
      "Epoch 00013: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9749 - accuracy: 0.7688 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 14/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9753 - accuracy: 0.7683\n",
      "Epoch 00014: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9753 - accuracy: 0.7683 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 15/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.7689\n",
      "Epoch 00015: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9747 - accuracy: 0.7689 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 16/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9749 - accuracy: 0.7688\n",
      "Epoch 00016: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9749 - accuracy: 0.7688 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 17/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9732 - accuracy: 0.7705\n",
      "Epoch 00017: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9732 - accuracy: 0.7705 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 18/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9742 - accuracy: 0.7695\n",
      "Epoch 00018: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 558ms/step - loss: 0.9742 - accuracy: 0.7695 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 19/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9720 - accuracy: 0.7717\n",
      "Epoch 00019: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9720 - accuracy: 0.7717 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 20/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9749 - accuracy: 0.7688\n",
      "Epoch 00020: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9749 - accuracy: 0.7688 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 21/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9759 - accuracy: 0.7677\n",
      "Epoch 00021: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9759 - accuracy: 0.7677 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 22/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9763 - accuracy: 0.7674\n",
      "Epoch 00022: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9763 - accuracy: 0.7674 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 23/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9756 - accuracy: 0.7681\n",
      "Epoch 00023: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9756 - accuracy: 0.7681 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 24/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9734 - accuracy: 0.7702\n",
      "Epoch 00024: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9734 - accuracy: 0.7702 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 25/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9783 - accuracy: 0.7653\n",
      "Epoch 00025: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9783 - accuracy: 0.7653 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 26/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9737 - accuracy: 0.7700\n",
      "Epoch 00026: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9737 - accuracy: 0.7700 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 27/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.7686\n",
      "Epoch 00027: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9751 - accuracy: 0.7686 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 28/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9728 - accuracy: 0.7708\n",
      "Epoch 00028: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9728 - accuracy: 0.7708 - val_loss: 0.9932 - val_accuracy: 0.7505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9725 - accuracy: 0.7712\n",
      "Epoch 00029: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9725 - accuracy: 0.7712 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 30/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.7690\n",
      "Epoch 00030: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9746 - accuracy: 0.7690 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 31/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9769 - accuracy: 0.7668\n",
      "Epoch 00031: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9769 - accuracy: 0.7668 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 32/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9769 - accuracy: 0.7668\n",
      "Epoch 00032: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9769 - accuracy: 0.7668 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 33/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9743 - accuracy: 0.7694\n",
      "Epoch 00033: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9743 - accuracy: 0.7694 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 34/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9747 - accuracy: 0.7689\n",
      "Epoch 00034: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9747 - accuracy: 0.7689 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 35/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.7686\n",
      "Epoch 00035: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9751 - accuracy: 0.7686 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 36/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.7686\n",
      "Epoch 00036: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9751 - accuracy: 0.7686 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 37/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9737 - accuracy: 0.7700\n",
      "Epoch 00037: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9737 - accuracy: 0.7700 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 38/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9749 - accuracy: 0.7688\n",
      "Epoch 00038: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9749 - accuracy: 0.7688 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 39/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9726 - accuracy: 0.7711\n",
      "Epoch 00039: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9726 - accuracy: 0.7711 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 40/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9743 - accuracy: 0.7694\n",
      "Epoch 00040: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 557ms/step - loss: 0.9743 - accuracy: 0.7694 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 41/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.9765 - accuracy: 0.7671\n",
      "Epoch 00041: val_accuracy did not improve from 0.75048\n",
      "262/262 [==============================] - 146s 556ms/step - loss: 0.9765 - accuracy: 0.7671 - val_loss: 0.9932 - val_accuracy: 0.7505\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting model with early stopping and checkpoint save\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_test, y_test), callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the history.history dict to a pandas DataFrame\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# Save to json for plots \n",
    "hist_json_file = 'VGG16.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show metrics\n",
    "predictions = model.predict([X_test])\n",
    "y_pred = predictions.argmax(axis=1).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot train and test validation of loss values and accuracy values\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'r--', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r--', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.ylim([0,1.5])\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC binary label reshaping\n",
    "y_pred_roc = (y_pred[:,None] == np.arange(y_pred.max()+1)).astype(int)\n",
    "y_test_roc = (y_test[:,None] == np.arange(y_test.max()+1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC\n",
    "def plot_roc(y_test, y_pred):\n",
    "    # Plot linewidth.\n",
    "    lw = 2\n",
    "    n_classes = len(y_pred_roc[0])\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_roc[:, i], y_pred_roc[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_roc.ravel(), y_pred_roc.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(1)\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(y_test_roc,y_pred_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(matrix, index = [i for i in range(len(np.unique(y_test)))],\n",
    "                  columns = [i for i in range(len(np.unique(y_test)))])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
